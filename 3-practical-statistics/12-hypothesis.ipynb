{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis testing and Confidence Intervals allow to use only sample data to draw conclusions about the entire population\n",
    "\n",
    "![h0](12-h0.png)\n",
    "\n",
    "![errors](hypo-errors.png)\n",
    "\n",
    "\n",
    "# Type I Errors\n",
    "\n",
    "Type I errors have the following features:\n",
    "\n",
    "1. You should set up your null and alternative hypotheses, so that the worse of your errors is the type I error.\n",
    "2. They are denoted by the symbol α.\n",
    "3. The definition of a type I error is: Deciding the alternative H_1 is true, when actually H_0 is true.\n",
    "4. Type I errors are often called false positives.\n",
    "\n",
    "# Type II Errors\n",
    "\n",
    "1. They are denoted by the symbol β.\n",
    "2. The definition of a type II error is: Deciding the null H_0 is true, when actually H_1 is true.\n",
    "3. Type II errors are often called false negatives.\n",
    "\n",
    "\n",
    "In the most extreme case, we can always choose one hypothesis (say always choosing the null) to ensure that a particular error never occurs (never a type I error assuming we always choose the null). However, more generally, there is a relationship where with a single set of data decreasing your chance of one type of error, increases the chance of the other error occurring.\n",
    "\n",
    "In most cases, we set a threshold of type 1 errors, while maintaining a low percentage of type 2 errors\n",
    "\n",
    "Hypothesis is to understand the population, not statistics\n",
    "\n",
    "There are 2 ways to choose a hypothesis:\n",
    "1. simpulate sampling distribtion of our statistics, and see whether our hypothesis is consistent across our sampling distribution\n",
    "2. simulate what's possible under the null, and see if data is consistents whith under the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo's value is 1.23\n"
     ]
    }
   ],
   "source": [
    "# first approach\n",
    "mean = []\n",
    "for _ in range(10000):\n",
    "    bootsample = sample_df.sample(150, replace=True)\n",
    "    mean.append(bootsample.height.mean())\n",
    "    \n",
    "np.percentile(means, 2.5), np.percentile(means, 97.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second approach\n",
    "# first approach\n",
    "mean = []\n",
    "for _ in range(10000):\n",
    "    bootsample = sample_df.sample(150, replace=True)\n",
    "    mean.append(bootsample.height.mean())\n",
    "    \n",
    "np.std(means)\n",
    "null_vals = np.random.normal(70, np.std(means), 10000)\n",
    "plt.hist(null_vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of a p-value is the probability of observing your statistic (or one more extreme in favor of the alternative) if the null hypothesis is true.\n",
    "\n",
    "H_0: m >= 70, H_1: m < 70:\n",
    "(null_vals < sample_mean).mean()\n",
    "\n",
    "H_0: m <= 70, H_1: m > 70:\n",
    "(null_vals > sample_mean).mean()\n",
    "\n",
    "H_0: m = 70, H_1: m != 70:\n",
    "(null_vals < sample_mean).mean() + (null_vals + 70 + (70 - sample_mean)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is the probability of getting our statistic or a more extreme value if the null is true.\n",
    "\n",
    "Therefore, small p-values suggest our null is not true. Rather, our statistic is likely to have come from a different distribution than the null.\n",
    "\n",
    "When the p-value is large, we have evidence that our statistic was likely to come from the null hypothesis. Therefore, we do not have evidence to reject the null.\n",
    "\n",
    "By comparing our p-value to our type I error threshold (\\alphaα), we can make our decision about which hypothesis we will choose.\n",
    "\n",
    "$$ pval \\leq \\alpha \\Rightarrow pval≤α⇒ Reject H_0H \n",
    "0 $$\n",
    "​\t \n",
    "\n",
    "$$pval > \\alpha \\Rightarrowpval>α⇒ Fail to Reject H_0H \n",
    "0 $$\n",
    "​\t\n",
    "\n",
    "When performing more than one hypothesis test, your type I error compounds. In order to correct for this, a common technique is called the Bonferroni correction. This correction is very conservative, but says that your new type I error rate should be the error rate you actually want divided by the number of tests you are performing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
